# BytePiece
BytePiece是一个bytes-based的Unigram分词器。由于采用了新的训练算法，所以压缩率通常比现有tokenizer更高。此外，它直接操作文本的utf-8 bytes，几乎不进行任何的预处理，所以更加纯粹和语言无关。

## 性质

理想的Tokenizer及其训练算法，应该具备以下特点：
- 无损重构
- 高压缩率
- 语言无关
- 数据驱动
- 训练友好

## 原理

## 安装

## 使用

## 引用

## 交流
